{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.9.0\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2021 ETH Zurich and University of Bologna.\n",
    "# Licensed under the Apache License, Version 2.0, see https://www.apache.org/licenses/LICENSE-2.0 for details.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import os\n",
    "import logging\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "\n",
    "# set global seeds for reproducibility\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Setting parameters for plotting\n",
    "plt.rcParams['figure.figsize'] = (15.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train dataset: (50000, 32, 32, 3)\n",
      "Shape of train labels: (50000, 1)\n",
      "Shape of test dataset: (10000, 32, 32, 3)\n",
      "Shape of test labels: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load Fashion-Mnist dataset, we can use Tensorflow for this\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# we save the pixels before normalization for plotting\n",
    "train_images_float = train_images.astype(np.float32)\n",
    "test_images_float = test_images.astype(np.float32)\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images.astype(np.float32) / 255.0\n",
    "test_images = test_images.astype(np.float32) / 255.0\n",
    "\n",
    "print(\"Shape of train dataset: {}\".format(train_images.shape))\n",
    "print(\"Shape of train labels: {}\".format(train_labels.shape))\n",
    "print(\"Shape of test dataset: {}\".format(test_images.shape))\n",
    "print(\"Shape of test labels: {}\".format(test_labels.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Keras model\n",
    "The input data is in the range of [0, 255]. We need to rescale the input data to the range of [0, 1] before feeding it to the model because the model should train on normalized and standardized data. We can do this by dividing the input data by 255. Thus, we ensure that all features are in the same range. We create a simple Keras model with one convolutional layers and a dense layer. The model is compiled with the Adam optimizer and the categorical cross-entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture (version 1 - simple model)\n",
    "# fp_model = tf.keras.Sequential([\n",
    "#   tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "#   tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "#   tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "#   tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#   tf.keras.layers.Flatten(),\n",
    "#   tf.keras.layers.Dense(10)\n",
    "# ])\n",
    "\n",
    "fp_model = tf.keras.Sequential([\n",
    "    # Reduced number of filters slightly\n",
    "    layers.Conv2D(12, (3, 3), activation='relu', input_shape=(32, 32, 3), padding='same'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(12, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    # Keep the same structure but with reduced parameters in the dense layer\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(48, activation='relu'),  # Reduced from 64 to 48\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "fp_model.compile(optimizer='adam',\n",
    "                # the loss function is the sparse categorical cross-entropy\n",
    "                # loss. It is used when there are two or more label classes. \n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 12)        336       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 12)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 12)        1308      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 12)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 48)                36912     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                490       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,046\n",
      "Trainable params: 39,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# View the model summary\n",
    "fp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sever\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 25s 15ms/step - loss: 1.5897 - accuracy: 0.4337 - val_loss: 1.3751 - val_accuracy: 0.5024\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 1.2899 - accuracy: 0.5407 - val_loss: 1.2107 - val_accuracy: 0.5755\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.1708 - accuracy: 0.5864 - val_loss: 1.1633 - val_accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0982 - accuracy: 0.6160 - val_loss: 1.1072 - val_accuracy: 0.6163\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.0490 - accuracy: 0.6337 - val_loss: 1.0954 - val_accuracy: 0.6192\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0069 - accuracy: 0.6484 - val_loss: 1.0410 - val_accuracy: 0.6361\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9693 - accuracy: 0.6600 - val_loss: 1.0619 - val_accuracy: 0.6311\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9465 - accuracy: 0.6663 - val_loss: 1.0176 - val_accuracy: 0.6430\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9168 - accuracy: 0.6783 - val_loss: 1.0094 - val_accuracy: 0.6501\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.8949 - accuracy: 0.6890 - val_loss: 1.0023 - val_accuracy: 0.6536\n"
     ]
    }
   ],
   "source": [
    "# Train the model (this will take a while)\n",
    "# The early stopping (es) callback will stop the training when the validation loss stops improving\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = fp_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model so we can use it later\n",
    "# without having to retrain it\n",
    "\n",
    "# check if 'model' directory exists\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "fp_model.save('models/fmnist_model_f32.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the keras model to a tflite model\n",
    "We can convert the keras model to a tflite model by using the `tf.lite.TFLiteConverter.from_keras_model_file()` function. After converting the model, we can save it to a file. Furthermore, we compare the size of the keras model and the tflite model. The difference is due to the fact that we have a lot of metadata in the keras model which is not present in the tflite model, such as the model architecture, optimizer, loss function, etc. This is also why you cannot call the `model.summary()` function on the tflite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Sever\\AppData\\Local\\Temp\\tmpynj252c0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Sever\\AppData\\Local\\Temp\\tmpynj252c0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 Model size without quantization: 503 KB\n",
      "TFLite Model size without quantization: 155 KB\n",
      "\n",
      "Reduction in file size by a factor of 3.231860\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TFLite without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(fp_model)\n",
    "fp_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"models/fmnist_model_f32.tflite\", \"wb\").write(fp_tflite_model)\n",
    "\n",
    "# Show the model size for the non-quantized HDF5 model\n",
    "fp_h5_in_kb = os.path.getsize('models/fmnist_model_f32.h5') / 1024\n",
    "print(\"HDF5 Model size without quantization: %d KB\" % fp_h5_in_kb)\n",
    "\n",
    "# Show the model size for the non-quantized TFLite model\n",
    "fp_tflite_in_kb = os.path.getsize('models/fmnist_model_f32.tflite') / 1024\n",
    "print(\"TFLite Model size without quantization: %d KB\" % fp_tflite_in_kb)\n",
    "\n",
    "# Determine the reduction in model size\n",
    "print(\"\\nReduction in file size by a factor of %f\" % (fp_h5_in_kb / fp_tflite_in_kb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize with dynamic range optimization\n",
    "We convert the Keras model to an float32 tflite model with dynamic range optimization. Dynamic range quantization is a technique that uses the full range of the data type to represent the weights and activations. This is done by calculating the range of the weights and activations and then scaling them to the full range of the data type. This is done by using the `tf.lite.Optimize.DEFAULT` flag which enables quantization of all fixed parameters. However, this only quantizes static parameters such as weights and biases. The input and output tensors are not quantized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Sever\\AppData\\Local\\Temp\\tmpysakah9p\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Sever\\AppData\\Local\\Temp\\tmpysakah9p\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was saved at location: c:\\Users\\Sever\\ML_on_MCU\\models\\fmnist_model_quant8_dynR.tflite\n"
     ]
    }
   ],
   "source": [
    "# Convert the model to TFLite with quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(fp_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dynR_quant_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(\"models/fmnist_model_quant8_dynR.tflite\", \"wb\").write(dynR_quant_tflite_model)\n",
    "\n",
    "\n",
    "print(\"Model was saved at location: %s\" % os.path.abspath('models/fmnist_model_quant8_dynR.tflite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=dynR_quant_tflite_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize the model to 8-bit integer precision\n",
    "We can also quantize the model to **full** 8-bit integer precision. This will reduce the model size and improve the inference speed. To quantize the variable data (such as model input/output and intermediates between layers), you need to provide a `RepresentativeDataset`. This is a generator function that provides a set of input data that's large enough to represent typical values. It allows the converter to estimate a dynamic range for all the variable data. (The dataset does not need to be unique compared to the training or evaluation dataset.) To support multiple inputs, each representative data point is a list and elements in the list are fed to the model according to their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Sever\\AppData\\Local\\Temp\\tmpuq4nqiwo\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Sever\\AppData\\Local\\Temp\\tmpuq4nqiwo\\assets\n",
      "C:\\Users\\Sever\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(fp_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant_int8 = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_int8)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was saved at location: c:\\Users\\Sever\\ML_on_MCU\\models\\fmnist_full_quant.tflite\n"
     ]
    }
   ],
   "source": [
    "# Save the quantized model to disk\n",
    "open(\"models/fmnist_full_quant.tflite\", \"wb\").write(tflite_model_quant_int8)\n",
    "\n",
    "print(\"Model was saved at location: %s\" % os.path.abspath('models/fmnist_full_quant.tflite'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the model to a C header file for use on the MCU\n",
    "We need to store the model parameters in a C header file so that we can run inference on the microcontroller with new input data (i.e.) from the testset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "    c_str = ''\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    # Add array length at top of file\n",
    "    c_str += '\\nstatic const unsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'static const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data) :\n",
    "\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formatting so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "            hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "            hex_str += '\\n '\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_model_name = 'q8fmnist'\n",
    "# check if dir 'cfiles' exists, if not create it\n",
    "if not os.path.exists('cfiles'):\n",
    "    os.makedirs('cfiles')\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open('cfiles/' + c_model_name + '.h', 'w') as file:\n",
    "    file.write(hex_to_c_array(tflite_model_quant_int8, c_model_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving test data used for inference on the MCU\n",
    "Additionally, we will save some samples from the test set which we will send via UART to the microcontroller. The microcontroller will then perform inference on these samples and send the results back to the host computer via a Python script that we prepared for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the test data as numpy arrays\n",
    "np.save('x_test_cifar.npy', test_images_float.astype(np.uint8))\n",
    "np.save('y_test_cifar.npy', test_labels.astype(np.uint8))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
